{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC01yKDJF5u",
        "outputId": "c0cc5333-b097-4771-835e-09fd074415b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
            "Collecting pandas>=0.24 (from catboost)\n",
            "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from catboost) (1.14.1)\n",
            "Collecting plotly (from catboost)\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: six in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.24->catboost)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24->catboost)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.4)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
            "  Downloading narwhals-1.29.0-py3-none-any.whl.metadata (10 kB)\n",
            "Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
            "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
            "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/11.5 MB 2.8 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 1.0/11.5 MB 3.1 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.8/11.5 MB 3.4 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 2.1/11.5 MB 3.3 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 2.6/11.5 MB 2.6 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 3.4/11.5 MB 2.7 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 3.9/11.5 MB 2.7 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 4.7/11.5 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 5.2/11.5 MB 2.9 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 5.8/11.5 MB 2.8 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 6.0/11.5 MB 2.8 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 6.6/11.5 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 6.6/11.5 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 6.6/11.5 MB 2.6 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 6.6/11.5 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 7.3/11.5 MB 2.1 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 7.9/11.5 MB 2.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.7/11.5 MB 2.3 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 9.4/11.5 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.0/11.5 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.0/11.5 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.2/11.5 MB 2.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.2/11.5 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.0/11.5 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.3/11.5 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.5/11.5 MB 2.1 MB/s eta 0:00:00\n",
            "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/14.8 MB 3.3 MB/s eta 0:00:05\n",
            "   -- ------------------------------------- 1.0/14.8 MB 2.3 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 1.6/14.8 MB 2.6 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 2.1/14.8 MB 2.7 MB/s eta 0:00:05\n",
            "   ------- -------------------------------- 2.9/14.8 MB 2.7 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 3.7/14.8 MB 2.8 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 4.2/14.8 MB 2.9 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 4.5/14.8 MB 2.8 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 5.0/14.8 MB 2.6 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 5.5/14.8 MB 2.6 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 5.5/14.8 MB 2.6 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 5.8/14.8 MB 2.3 MB/s eta 0:00:05\n",
            "   --------------- ------------------------ 5.8/14.8 MB 2.3 MB/s eta 0:00:05\n",
            "   ---------------- ----------------------- 6.0/14.8 MB 2.0 MB/s eta 0:00:05\n",
            "   ----------------- ---------------------- 6.6/14.8 MB 2.0 MB/s eta 0:00:05\n",
            "   ------------------- -------------------- 7.1/14.8 MB 2.1 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 7.9/14.8 MB 2.2 MB/s eta 0:00:04\n",
            "   ---------------------- ----------------- 8.4/14.8 MB 2.2 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 9.2/14.8 MB 2.2 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 9.7/14.8 MB 2.3 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 10.5/14.8 MB 2.3 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 11.3/14.8 MB 2.4 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 11.8/14.8 MB 2.4 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 12.1/14.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 12.3/14.8 MB 2.3 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 12.3/14.8 MB 2.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 12.8/14.8 MB 2.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 13.1/14.8 MB 2.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.6/14.8 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 14.2/14.8 MB 2.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.8/14.8 MB 2.2 MB/s eta 0:00:00\n",
            "Downloading narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Installing collected packages: pytz, tzdata, narwhals, graphviz, plotly, pandas, catboost\n",
            "Successfully installed catboost-1.2.7 graphviz-0.20.3 narwhals-1.29.0 pandas-2.2.3 plotly-6.0.0 pytz-2025.1 tzdata-2025.1\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qdP96YYwl_N",
        "outputId": "0f711a09-e7fd-4bec-be50-cb40ffe927ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.9294496306630964\n",
            "R¬≤ Score: 0.9692978016070268\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(r\"C:\\Users\\KAVIN KUMAR\\Downloads\\EV_Performance_Dataset.csv\")\n",
        "\n",
        "# Define independent and dependent variables\n",
        "X = df.drop(columns=[\"Efficiency_Score\"])\n",
        "y = df[\"Efficiency_Score\"]\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train CatBoost Regressor\n",
        "model = CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, verbose=0, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R¬≤ Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m9xNMUaYIdvP"
      },
      "outputs": [],
      "source": [
        "# Save the CatBoost model as ONNX\n",
        "model.save_model(r\"C:\\Users\\KAVIN KUMAR\\Downloads\\catboost_model.onnx\", format=\"onnx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Efficiency Score: [87.137314]\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = r\"C:\\Users\\KAVIN KUMAR\\Downloads\\catboost_model.onnx\"  # Update with your actual path\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Example data point (without titles, just values)\n",
        "data_point = np.array([333.2218473,\t31.42047687,\t97\t,32.8533202\t,36.81469003\t,2441\t,66.32206791\t,118.9696365\t,21.19826862\t,43\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0,\t0\t,0\t,0\t,0\n",
        "]).astype(np.float32).reshape(1, -1)  # Reshape for batch dimension\n",
        "\n",
        "# Get the input name of the model\n",
        "input_name = session.get_inputs()[0].name\n",
        "\n",
        "# Run inference\n",
        "output = session.run(None, {input_name: data_point})\n",
        "\n",
        "# Print efficiency score prediction\n",
        "print(\"Predicted Efficiency Score:\", output[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction 1: Efficiency Score = 82.37850189208984\n",
            "Prediction 2: Efficiency Score = 82.37850189208984\n",
            "Prediction 3: Efficiency Score = 87.13731384277344\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = r\"C:\\Users\\KAVIN KUMAR\\Downloads\\catboost_model.onnx\"  # Update with actual path\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Define the input data (without column names)\n",
        "input_data = np.array([\n",
        "    [303.7086107,34.15969893,\t30,\t47.03309498,\t52.39974686,\t4295,\t41.34352582,\t161.3283347,\t23.23319467,\t36,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],  # Example 1\n",
        "    [303.7086107,34.15969893,\t30,\t47.03309498,\t52.39974686,\t4295,\t41.34352582,\t161.3283347,\t23.23319467,\t36,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],  # Example 2\n",
        "    [333.2218473,\t31.42047687,\t97\t,32.8533202\t,36.81469003\t,2441\t,66.32206791\t,118.9696365\t,21.19826862\t,43\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0,\t0\t,0\t,0\t,0]   # Example 3\n",
        "], dtype=np.float32)  # Convert to float32 for ONNX compatibility\n",
        "\n",
        "# Get the input name from the model\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "# Run predictions in a loop with a 10-second gap\n",
        "for i, data_point in enumerate(input_data):\n",
        "    # Reshape input to match the model's expected format\n",
        "    data_point = data_point.reshape(1, -1)  # Reshape to (1, num_features)\n",
        "\n",
        "    # Run inference\n",
        "    output = session.run([output_name], {input_name: data_point})[0]\n",
        "\n",
        "    # Print the predicted efficiency score\n",
        "    print(f\"Prediction {i+1}: Efficiency Score = {output[0][0]}\")\n",
        "\n",
        "    # Wait for 10 seconds before the next prediction\n",
        "    if i < len(input_data) - 1:\n",
        "        time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting google-api-core (from google-generativeai)\n",
            "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-api-python-client (from google-generativeai)\n",
            "  Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: protobuf in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-generativeai) (4.25.4)\n",
            "Requirement already satisfied: pydantic in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-generativeai) (2.9.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
            "  Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.66.1)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kavin kumar\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
            "Collecting protobuf (from google-generativeai)\n",
            "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 0.5/1.3 MB 2.8 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 0.8/1.3 MB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.3/1.3 MB 2.1 MB/s eta 0:00:00\n",
            "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl (13.1 MB)\n",
            "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/13.1 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/13.1 MB 1.1 MB/s eta 0:00:12\n",
            "   - -------------------------------------- 0.5/13.1 MB 1.1 MB/s eta 0:00:12\n",
            "   --- ------------------------------------ 1.0/13.1 MB 1.0 MB/s eta 0:00:12\n",
            "   ---- ----------------------------------- 1.3/13.1 MB 1.1 MB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 1.8/13.1 MB 1.3 MB/s eta 0:00:09\n",
            "   ------ --------------------------------- 2.1/13.1 MB 1.4 MB/s eta 0:00:09\n",
            "   ------- -------------------------------- 2.4/13.1 MB 1.4 MB/s eta 0:00:08\n",
            "   -------- ------------------------------- 2.6/13.1 MB 1.4 MB/s eta 0:00:08\n",
            "   --------- ------------------------------ 3.1/13.1 MB 1.4 MB/s eta 0:00:07\n",
            "   ---------- ----------------------------- 3.4/13.1 MB 1.5 MB/s eta 0:00:07\n",
            "   ------------ --------------------------- 3.9/13.1 MB 1.5 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 4.2/13.1 MB 1.5 MB/s eta 0:00:06\n",
            "   -------------- ------------------------- 4.7/13.1 MB 1.6 MB/s eta 0:00:06\n",
            "   ---------------- ----------------------- 5.2/13.1 MB 1.6 MB/s eta 0:00:05\n",
            "   ----------------- ---------------------- 5.8/13.1 MB 1.7 MB/s eta 0:00:05\n",
            "   ------------------ --------------------- 6.0/13.1 MB 1.7 MB/s eta 0:00:05\n",
            "   ------------------- -------------------- 6.3/13.1 MB 1.7 MB/s eta 0:00:05\n",
            "   -------------------- ------------------- 6.8/13.1 MB 1.7 MB/s eta 0:00:04\n",
            "   ---------------------- ----------------- 7.3/13.1 MB 1.7 MB/s eta 0:00:04\n",
            "   ------------------------ --------------- 7.9/13.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 8.1/13.1 MB 1.7 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 8.7/13.1 MB 1.8 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 8.9/13.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 9.4/13.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ------------------------------ --------- 10.0/13.1 MB 1.8 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 10.5/13.1 MB 1.8 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 11.0/13.1 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 11.8/13.1 MB 1.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.3/13.1 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.6/13.1 MB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 13.1/13.1 MB 1.9 MB/s eta 0:00:00\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl (169 kB)\n",
            "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
            "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
            "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
            "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.5/4.3 MB 3.4 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 1.3/4.3 MB 3.4 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.8/4.3 MB 3.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 2.6/4.3 MB 3.1 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 2.9/4.3 MB 3.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 3.4/4.3 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 3.9/4.3 MB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.3/4.3 MB 2.6 MB/s eta 0:00:00\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: uritemplate, pyasn1, protobuf, httplib2, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.4\n",
            "    Uninstalling protobuf-4.25.4:\n",
            "      Successfully uninstalled protobuf-4.25.4\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.66.1\n",
            "    Uninstalling grpcio-1.66.1:\n",
            "      Successfully uninstalled grpcio-1.66.1\n",
            "Successfully installed cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.24.1 google-api-python-client-2.162.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 googleapis-common-protos-1.69.0 grpcio-1.70.0 grpcio-status-1.70.0 httplib2-0.22.0 proto-plus-1.26.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 uritemplate-4.1.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction 1: Efficiency Score = 87.13731384277344\n",
            "‚úÖ Efficiency is within optimal range. Continuing...\n",
            "\n",
            "Prediction 2: Efficiency Score = 82.4981460571289\n",
            "‚ö†Ô∏è Efficiency below threshold! Calling LLM for analysis...\n",
            "\n",
            "üîç **Generated Report:**\n",
            " ## EV Efficiency Anomaly Report\n",
            "\n",
            "The EV efficiency score is below the optimal threshold, suggesting potential issues within the system. Elevated Battery and Motor Temperatures, coupled with a moderate SOC and Motor Speed, could indicate thermal management inefficiencies or increased internal resistance. Further investigation into the Cooling System and potential for Dischg_Overcurrent_Level_2 activation is warranted. Monitoring these parameters closely for the next 2 weeks and scheduling a service center visit if the issue persists is advisable.\n",
            "\n",
            "Prediction 3: Efficiency Score = 82.37850189208984\n",
            "‚ö†Ô∏è Efficiency below threshold! Calling LLM for analysis...\n",
            "\n",
            "üîç **Generated Report:**\n",
            " ## EV Efficiency Anomaly Report\n",
            "\n",
            "The EV's efficiency score of 82.38 is below the optimal 87 threshold, indicating a performance issue. High discharge overcurrent (Dischg_Overcurrent_Level_1 = 1.0) and low cell voltage (Cell_Volt_Low_Level_1 = 1.0) are potential contributing factors. This combination suggests the battery may be struggling to deliver power efficiently, potentially due to cell imbalance or degradation. A slight deviation in battery/motor temperature could contribute but has less significance. Schedule a service center visit within the next week for a comprehensive battery health check.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# Configure Gemini API\n",
        "genai.configure(api_key=\"AIzaSyA7ZmjqgqyNjb1JmjlcLgFM1XPO2Rx32gs\")\n",
        "\n",
        "# Function to analyze low efficiency issues\n",
        "def analyze_issue(input_data, efficiency_score):\n",
        "    prompt = f\"\"\"\n",
        "    You are an virtual EV statistical data analysis agent, you get data from various EVs and analyze the efficiency of the EVs.\n",
        "    \n",
        "    Analyze the following EV efficiency anomaly. The efficiency score is {efficiency_score}, which is below the optimal threshold of 87.\n",
        "    The parameters format are : Battery_Voltage\tBattery_Temperature\tSOC\tBattery_Current\tMotor_Temperature\tMotor_Speed\tPower_Output\tTorque\tCharging_Power\tCharging_Time\tChg_Overcurrent_Level_1\tChg_Overcurrent_Level_2\tDischg_Overcurrent_Level_1\tDischg_Overcurrent_Level_2\tCell_Volt_High_Level_1\tCell_Volt_High_Level_2\tCell_Volt_Low_Level_1\tCell_Volt_Low_Level_2\tSum_Volt_High_Level_1\tSum_Volt_Low_Level_2\tChg_Temp_High_Level_1\tChg_Temp_Low_Level_2\tDischg_Temp_High_Level_1\tDischg_Temp_Low_Level_2\tShort_Circuit_Protect_Fault\tCommunication_Failure\tCooling_System_Failure\tEfficiency_Score\n",
        "    Given the input parameters:\n",
        "    \n",
        "    {json.dumps(input_data, indent=2)}\n",
        "    \n",
        "    Provide a detailed report explaining the potential root causes in crisp not exceeding 5 to 7 lines, Try to say at what amount of period will taking the EV to service center be fine in a line in crisp.\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text  # Extract and return the LLM response\n",
        "\n",
        "def analyze_issue_user(input_data, efficiency_score):\n",
        "    prompt = f\"\"\"\n",
        "    You are an virtual EV statistical data analysis agent, you get data from various EVs and analyze the efficiency of the EVs.\n",
        "    \n",
        "    Analyze the following EV efficiency anomaly. The efficiency score is {efficiency_score}, which is below the optimal threshold of 87.\n",
        "    The parameters format are : Battery_Voltage\tBattery_Temperature\tSOC\tBattery_Current\tMotor_Temperature\tMotor_Speed\tPower_Output\tTorque\tCharging_Power\tCharging_Time\tChg_Overcurrent_Level_1\tChg_Overcurrent_Level_2\tDischg_Overcurrent_Level_1\tDischg_Overcurrent_Level_2\tCell_Volt_High_Level_1\tCell_Volt_High_Level_2\tCell_Volt_Low_Level_1\tCell_Volt_Low_Level_2\tSum_Volt_High_Level_1\tSum_Volt_Low_Level_2\tChg_Temp_High_Level_1\tChg_Temp_Low_Level_2\tDischg_Temp_High_Level_1\tDischg_Temp_Low_Level_2\tShort_Circuit_Protect_Fault\tCommunication_Failure\tCooling_System_Failure\tEfficiency_Score\n",
        "    Given the input parameters:\n",
        "    \n",
        "    {json.dumps(input_data, indent=2)}\n",
        "    \n",
        "    Now in one line tell user more conviniently so that they wont get threatened with this message but notified to visit the service center with \"level 1\" indication if its not a big issue and visiting store in a week else \"level 2\" if its a big issue visiting store within a day is necessary.\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "    response_user = model.ge\n",
        "\n",
        "    return response.text  # Extract and return the LLM response\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = r\"C:\\Users\\KAVIN KUMAR\\Downloads\\catboost_model.onnx\"  # Update path\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Define the input data (without column names)\n",
        "input_data = np.array([\n",
        "    [333.2218473,\t31.42047687,\t97\t,32.8533202\t,36.81469003\t,2441\t,66.32206791\t,118.9696365\t,21.19826862\t,43\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0,\t0\t,0\t,0\t,0],  # Example 1\n",
        "    [335.8794548\t,56.71891032,46\t,25.55073651\t,62.50450556\t,4406\t,61.53898666\t,154.5703016\t,20.8919481\t,58\t,1\t,0\t,0\t,1\t,0\t,1\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0\t,0],  # Example 2\n",
        "    [303.7086107, 34.15969893, 30, 47.03309498, 52.39974686, 4295, 41.34352582, 161.3283347, 23.23319467, 36, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   # Example 3\n",
        "], dtype=np.float32)  # Convert to float32 for ONNX compatibility\n",
        "\n",
        "# Get the input and output names from the model\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "# Run predictions and analyze anomalies\n",
        "for i, data_point in enumerate(input_data):\n",
        "    # Reshape input to match model's expected format\n",
        "    data_point = data_point.reshape(1, -1)  # Reshape to (1, num_features)\n",
        "\n",
        "    # Run inference\n",
        "    output = session.run([output_name], {input_name: data_point})[0]\n",
        "    efficiency_score = output[0][0]\n",
        "\n",
        "    print(f\"Prediction {i+1}: Efficiency Score = {efficiency_score}\")\n",
        "\n",
        "    # Check efficiency threshold\n",
        "    if efficiency_score < 87:\n",
        "        print(\"‚ö†Ô∏è Efficiency below threshold! Calling LLM for analysis...\")\n",
        "        report = analyze_issue(data_point.tolist()[0], efficiency_score)\n",
        "        print(\"\\nüîç **Generated Report to store:**\\n\", report)\n",
        "        print(\"\\nüîç **Generated Report to user:**\\n\", report)\n",
        "    else:\n",
        "        print(\"‚úÖ Efficiency is within optimal range. Continuing...\\n\")\n",
        "\n",
        "    # Wait before the next prediction\n",
        "    if i < len(input_data) - 1:\n",
        "        time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
